---
title:  Day 2
layout: singletrack
tagline: 
show_abstracts: true
talks:
- title: "Breakfast, Windows on the Green and Chart Room"
  start: "7:30"
  end: "9:00"
- title: "Registration Desk"
  start: "8:00"
  end: "10:00"
- title: Invited Talk
  start: "09:00"
  end: "10:30"
  room: Crystal Ballroom 1, 2
  author:
  - family: Rudin
    given: Cynthia
    institute: Duke University
    prezi: aistatsrudin 
    abstract: "Is there always a tradeoff between accuracy and interpretability? This is a very old AI question. Many people have claimed that they have investigated the answer to this question, but it is not clear that these attempts have been truly serious. If we try to investigate this claim by comparing interpretable modeling algorithms (like decision trees - say CART, C4.5) to a black box method that optimizes only accuracy (SVM or neural networks), we will not find the answer. This is not a fulfilling comparison - the methods for producing interpretable models are greedy myopic methods with no global objective, whereas the black box algorithms have global objectives and principled optimization routines. In order to actually answer this question, we would have to compare an 'optimal' interpretable model to an optimal black box model. This means we actually need optimality for interpretable models. This, of course, leads to computationally hardness, which scares us. On the other hand, we have computing power like never before. So do we truly know what we are afraid of any more? In this talk I will discuss algorithms for interpretable machine learning. Some of these algorithms are designed to create certificates of nearness to optimality. I will focus on some of our most recent work, including (1) work on optimal rule list models using customized bounds and data structures (these are an alternative to CART) (2) work on optimal scoring systems (alternatives to logistic regression + rounding). Further, since we have methods that can produce optimal or near-optimal models, we can use them to produce interesting new forms of interpretable models. These new forms were simply not possible before, since they are almost impossible to produce using traditional techniques (like greedy splitting and pruning). In particular: (3) Falling rule lists, (4) Causal falling rule lists, and (5) Cost-effective treatment regimes. Work on (1) is joint with postdoc Elaine Angelino, students Nicholas Larus-Stone and Daniel Alabi, and colleague Margo Seltzer. Work on (2) is joint with student Berk Ustun. Work on (3) and (4) are joint with students Fulton Wang and Chaofan Chen, and (5) is an AISTATS 2017 paper that is joint work with student Himabindu Lakkaraju."
    bio: "Cynthia Rudin is an associate professor of computer science and electrical and computer engineering at Duke University, and directs the Prediction Analysis Lab. Her interests are in machine learning, data mining, applied statistics, and knowledge discovery (Big Data). Her application areas are in energy grid reliability, healthcare, and computational criminology. Previously, Prof. Rudin held positions at MIT, Columbia, and NYU. She holds an undergraduate degree from the University at Buffalo where she received the College of Arts and Sciences Outstanding Senior Award in Sciences and Mathematics, and three separate outstanding senior awards from the departments of physics, music, and mathematics. She received a PhD in applied and computational mathematics from Princeton University. She is the recipient of the 2013 and 2016 INFORMS Innovative Applications in Analytics Awards, an NSF CAREER award, was named as one of the 'Top 40 Under 40' by Poets and Quants in 2015, and was named by Businessinsider.com as one of the 12 most impressive professors at MIT in 2015. Work from her lab has won 10 best paper awards in the last 5 years. Her work has been featured in Businessweek, The Wall Street Journal, the New York Times, the Boston Globe, the Times of London, Fox News (Fox & Friends), the Toronto Star, WIRED Science, U.S. News and World Report, Slashdot, CIO magazine, Boston Public Radio, and on the cover of IEEE Computer. She is past chair of the INFORMS Data Mining Section, and is currently chair-elect of the Statistical Learning and Data Science section of the American Statistical Association."
- title: "Coffee Break"
  start: "10:00"
  end: "10:30"
  room: Crystal Atrium
- title: "Theory"
  start: "10:00"
  end: "10:30"
  room: Crystal Ballroom 1, 2
  abstract: "<i>Session Chair: Sanjoy Dasgupta</i><br>94 Phase Retrieval Meets Statistical Learning Theory: A Flexible Convex Relaxation
68 A Sub-Quadratic Exact Medoid Algorithm<br>
456 On the Interpretability of Conditional Probability Estimates in the Agnostic Setting<br>
209 Beta calibration: a well-founded and easily implemented improvement on logistic calibration for binary classifiers<br>"
- title: "Lunch on your own"
  start: "12:10"
  end: "14:00"
- title: "Registration Desk"
  start: "13:00"
  end: "15:00"
- title: "Approximate Inference and MCMC"
  start: "14:00"
  end: "15:40"
  room: Crystal Ballroom 1, 2 
  abstract: "<i>Session Chair: Simon Lacoste-Julien</i><br>
51 Annular Augmentation Sampling<br>
101 Removing Phase Transitions from Gibbs Measures<br>
170 Reparameterization Gradients through Acceptance-Rejection Sampling Algorithms<br>
174 Asymptotically exact inference in differentiable generative models"
- title: Coffee Break
  start: "15:40"
  end: "16:40"
  room: Crystal Atrium
- title: Poster Session (with light snacks)
  room: Crystal Ballroom 3, 4
  abstract: <a href="http://www.aistats.org/schedule.html#foo4">See poster list</a>
  start: "16:10"
  end: "19:00"
---


